{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515af962-dec6-45b1-874d-c43a9b08fa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cho, classif ensemble, sans réduction de dimension... ie fin de la partie 1 du papier IEEE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122cb047-2b36-412b-be0c-0faf412cd2d2",
   "metadata": {},
   "source": [
    "# FUCONE - tutorial to adopt an ensemble approach that relies on functional connectivity estimators - classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a36781-08c1-440a-bdf9-5deea07d03bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authors: Sylvain Chevallier <sylvain.chevallier@uvsq.fr>,\n",
    "#          Marie-Constance Corsi <marie.constance.corsi@gmail.com>\n",
    "# License: BSD (3-clause)\n",
    "\n",
    "import os.path as osp\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import gzip\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import ptitprince as pt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.linear_model import (\n",
    "    LogisticRegression,\n",
    ")\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score, cohen_kappa_score\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from pyriemann.spatialfilters import CSP\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "from pyriemann.classification import FgMDM\n",
    "\n",
    "from moabb.datasets import (\n",
    "    Cho2017\n",
    ")\n",
    "from moabb.paradigms import LeftRightImagery\n",
    "from moabb.pipelines.csp import TRCSP\n",
    "\n",
    "from fc_pipeline import (\n",
    "    FunctionalTransformer,\n",
    "    EnsureSPD,\n",
    "    FC_DimRed, #????\n",
    "    GetDataMemory,\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(action='ignore', category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad8c0e6-0849-4ec3-a451-0f13621e6ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# key-parameters\n",
    "basedir = os.getcwd()\n",
    "datasets = [Cho2017()]\n",
    "\n",
    "spectral_met = [\"cov\", \"imcoh\", \"instantaneous\"]\n",
    "print(\n",
    "    \"#################\" + \"\\n\"\n",
    "    \"List of pre-selected FC metrics: \" + \"\\n\" + str(spectral_met) + \"\\n\"\n",
    "    \"#################\"\n",
    ")\n",
    "freqbands = {\"defaultBand\": [8, 35]}\n",
    "print(\n",
    "    \"#################\" + \"\\n\"\n",
    "    \"List of pre-selected Frequency bands: \" + \"\\n\" + str(freqbands) + \"\\n\"\n",
    "    \"#################\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd2c6cb-1ad4-4c8c-bf2a-1bb3906d9717",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Baseline evaluation\n",
    "step_csp = [\n",
    "    (\"csp\", CSP(nfilter=6)),\n",
    "    (\n",
    "        \"optsvm\",\n",
    "        GridSearchCV(SVC(), {\"kernel\": (\"linear\", \"rbf\"), \"C\": [0.1, 1, 10]}, cv=3),\n",
    "    ),\n",
    "]\n",
    "step_mdm = [(\"fgmdm\", FgMDM(metric=\"riemann\", tsupdate=False))]\n",
    "\n",
    "\n",
    "# Riemannian geometry approach relying on the covariance \n",
    "step_cov = [\n",
    "    (\"tg\", TangentSpace(metric=\"riemann\")),\n",
    "    (\n",
    "        \"LogistReg\",\n",
    "        LogisticRegression(\n",
    "            penalty=\"elasticnet\", l1_ratio=0.15, intercept_scaling=1000.0, solver=\"saga\"\n",
    "        ),\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Riemannian geometry approach relying on functional connectivity estimators\n",
    "bs_fmin, bs_fmax = 8, 35\n",
    "ft = FunctionalTransformer(delta=1, ratio=0.5, method=\"cov\", fmin=bs_fmin, fmax=bs_fmax)\n",
    "step_fc = [\n",
    "    (\"tg\", TangentSpace(metric=\"riemann\")),\n",
    "    (\n",
    "        \"LogistReg\",\n",
    "        LogisticRegression(\n",
    "            penalty=\"elasticnet\", l1_ratio=0.15, intercept_scaling=1000.0, solver=\"saga\"\n",
    "        ),\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166ecc22-c100-44f3-87fe-49d6195e1040",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f288adb-3f3e-4331-9507-e1098ac0430a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c09938-9396-46c8-b37f-261aca80e85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Specific evaluation for ensemble learning - covariance & functional connectivity\n",
    "for d in datasets:\n",
    "    subj = d.subject_list\n",
    "\n",
    "    subj_cho = [14]#[14, 43, 50, 35, 3, 29, 7, 17, 40, 38] # @Sylvain: on peut réduire le nombre de sujets si tu veux\n",
    "    # precompute all metrics for datasets\n",
    "    print(\"\\n\\n\\n#################\\nPrecompute all metrics\\n#################\")\n",
    "    data_fc = {}\n",
    "    for f in freqbands:\n",
    "        fmin = freqbands[f][0]\n",
    "        fmax = freqbands[f][1]\n",
    "        subjects = subj\n",
    "        data_fc[f] = {}\n",
    "        for subject in tqdm(subj_cho, desc=\"subject\"):\n",
    "            data_fc[f][subject] = {}\n",
    "            paradigm = LeftRightImagery(fmin=fmin, fmax=fmax)\n",
    "            ep_, _, _ = paradigm.get_data(\n",
    "                    dataset=d, subjects=[subject], return_epochs=True\n",
    "                )\n",
    "            for sm in  tqdm(spectral_met, desc=\"met\"):\n",
    "                ft = FunctionalTransformer(\n",
    "                        delta=1, ratio=0.5, method=sm, fmin=fmin, fmax=fmax\n",
    "                    )\n",
    "                preproc = Pipeline(steps=[(\"ft\", ft), (\"spd\", EnsureSPD())])\n",
    "                data_fc[f][subject][sm] = preproc.fit_transform(ep_)\n",
    "    with gzip.open(\"metrics.gz\", \"w\") as f:\n",
    "            pickle.dump(data_fc, f)\n",
    "\n",
    "    print(\"\\n\\n\\n#################\\nCompute results\\n#################\")\n",
    "    dataset_res = list()\n",
    "    for f in freqbands:\n",
    "        fmin = freqbands[f][0]\n",
    "        fmax = freqbands[f][1]\n",
    "        subjects = subj\n",
    "        for subject in tqdm(subj_cho, desc=\"subject\"):\n",
    "            fmin = freqbands[\"defaultBand\"][0]\n",
    "            fmax = freqbands[\"defaultBand\"][1]\n",
    "            paradigm = LeftRightImagery(fmin=fmin, fmax=fmax)\n",
    "            ep_, _, _ = paradigm.get_data(\n",
    "                dataset=d, subjects=[subj[1]], return_epochs=True\n",
    "            )\n",
    "            nchan = ep_.info[\"nchan\"]\n",
    "\n",
    "            ppl_noDR, ppl_ens, baseline_ppl = {}, {}, {}\n",
    "            gd = GetDataMemory(subject, f, \"cov\", data_fc)\n",
    "            baseline_ppl[\"CSP+optSVM\"] = Pipeline(steps=[(\"gd\", gd)] + step_csp)\n",
    "            baseline_ppl[\"FgMDM\"] = Pipeline(steps=[(\"gd\", gd)] + step_mdm)\n",
    "            for sm in spectral_met:\n",
    "                gd = GetDataMemory(subject, f, sm, data_fc)\n",
    "                ft = FunctionalTransformer(\n",
    "                    delta=1, ratio=0.5, method=sm, fmin=fmin, fmax=fmax\n",
    "                )\n",
    "                if sm == \"cov\":\n",
    "                    ppl_noDR[\"cov+elasticnet\"] = Pipeline(\n",
    "                        steps=[(\"gd\", gd)] + step_cov\n",
    "                    )\n",
    "                else:\n",
    "                    pname_noDR = sm + \"+elasticnet\"\n",
    "                    ppl_noDR[pname_noDR] = Pipeline(\n",
    "                        steps=[(\"gd\", gd)] + step_fc\n",
    "                    )\n",
    "\n",
    "            ################ Ensemble from single features classif with elasticnet ################\n",
    "            noDR_estimators_best = [(n, ppl_noDR[n]) for n in ppl_noDR]\n",
    "  \n",
    "            cvkf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "            # ensemble with elasticnet\n",
    "            elastic_estimator = LogisticRegression(\n",
    "                penalty=\"elasticnet\",\n",
    "                l1_ratio=0.15,\n",
    "                intercept_scaling=1000.0,\n",
    "                solver=\"saga\",\n",
    "            )\n",
    "\n",
    "            scl_elastic_noDR_best = StackingClassifier(\n",
    "                estimators=noDR_estimators_best,\n",
    "                cv=cvkf,\n",
    "                n_jobs=1,\n",
    "                final_estimator=elastic_estimator,\n",
    "                stack_method=\"predict_proba\",\n",
    "            )\n",
    "            ppl_ens[\"FUCONE\"] = scl_elastic_noDR_best\n",
    "\n",
    "\n",
    "            all_ppl = {**baseline_ppl, **ppl_ens}\n",
    "\n",
    "            ###########################################################################\n",
    "            # Train and evaluate\n",
    "            _, y, metadata = paradigm.get_data(d, [subject], return_epochs=True)\n",
    "            X = np.arange(len(y))\n",
    "            for session in np.unique(metadata.session):\n",
    "                ix = metadata.session == session\n",
    "                cv = StratifiedKFold(5, shuffle=True, random_state=42)\n",
    "                le = LabelEncoder()\n",
    "                y_cv = le.fit_transform(y[ix])\n",
    "                X_ = X[ix]\n",
    "                y_ = y_cv\n",
    "                for idx, (train, test) in enumerate(cv.split(X_, y_)):\n",
    "                    for ppn, ppl in tqdm(\n",
    "                        all_ppl.items(), total=len(all_ppl), desc=\"pipelines\"\n",
    "                    ):\n",
    "                        cvclf = clone(ppl)\n",
    "                        cvclf.fit(X_[train], y_[train])\n",
    "                        yp = cvclf.predict(X_[test])\n",
    "                        acc = balanced_accuracy_score(y_[test], yp)\n",
    "                        auc = roc_auc_score(y_[test], yp)\n",
    "                        kapp = cohen_kappa_score(y_[test], yp)\n",
    "                        res_info = {\n",
    "                            \"subject\": subject,\n",
    "                            \"session\": \"session_0\",\n",
    "                            \"channels\": nchan,\n",
    "                            \"n_sessions\": 1,\n",
    "                            \"FreqBand\": \"defaultBand\",\n",
    "                            \"dataset\": d.code,\n",
    "                            \"fmin\": fmin,\n",
    "                            \"fmax\": fmax,\n",
    "                            \"samples\": len(y_),\n",
    "                            \"time\": 0.0,\n",
    "                            \"split\": idx,\n",
    "                        }\n",
    "                        res = {\n",
    "                            \"score\": auc,\n",
    "                            \"kappa\": kapp,\n",
    "                            \"accuracy\": acc,\n",
    "                            \"pipeline\": ppn,\n",
    "                            \"n_dr\": nchan,\n",
    "                            \"thres\": 0,\n",
    "                            **res_info,\n",
    "                        }\n",
    "                        dataset_res.append(res)\n",
    "                        if isinstance(ppl, StackingClassifier):\n",
    "                            for est_n, est_p in cvclf.named_estimators_.items():\n",
    "                                p = est_p.get_params()\n",
    "                                for step_est in p[\"steps\"]:\n",
    "                                    if isinstance(step_est[1], FC_DimRed):\n",
    "                                        thres, n_dr = p[step_est[0]].best_param_\n",
    "                                        break\n",
    "                                else:\n",
    "                                    thres, n_dr = 0, nchan\n",
    "                                ype = est_p.predict(X_[test])\n",
    "                                acc = balanced_accuracy_score(y_[test], ype)\n",
    "                                auc = roc_auc_score(y_[test], ype)\n",
    "                                kapp = cohen_kappa_score(y_[test], ype)\n",
    "                                res = {\n",
    "                                    \"score\": auc,\n",
    "                                    \"kappa\": kapp,\n",
    "                                    \"accuracy\": acc,\n",
    "                                    \"pipeline\": est_n,\n",
    "                                    \"thres\": thres,\n",
    "                                    \"n_dr\": n_dr,\n",
    "                                    **res_info,\n",
    "                                }\n",
    "                                dataset_res.append(res)\n",
    "    dataset_res = pd.DataFrame(dataset_res)\n",
    "    dataset_res.to_csv(\n",
    "        \"OptEnsemble.csv\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ce30b2-a52b-4976-8e6f-3eab49088476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot comparison between pipelines\n",
    "results_ensemble = pd.read_csv(\n",
    "    \"OptEnsemble.csv\"\n",
    ")\n",
    "list_fc_ens=[\"FUCONE\",\"CSP+optSVM\",\"FgMDM\",\"cov+elasticnet\",\"instantaneous+elasticnet\",\"imcoh+elasticnet\"]\n",
    "\n",
    "# plots FC vs ens\n",
    "plt.close(\"all\")\n",
    "plt.style.use(\"dark_background\")\n",
    "g = sns.catplot(\n",
    "    data=results_ensemble,\n",
    "    x=\"pipeline\",\n",
    "    y=\"score\",\n",
    "    kind=\"bar\",\n",
    "    #saturation=0.5,\n",
    "    order=list_fc_ens,\n",
    "    height=7,\n",
    "    aspect=2, #1.5\n",
    ")\n",
    "plt.ylim((0.6, 1))\n",
    "plt.xticks(range(len(results_ensemble[\"pipeline\"].unique())),\n",
    "           fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.xlabel(\"Pipeline\", fontsize=21)\n",
    "plt.ylabel(\"Score\", fontsize=21)\n",
    "plt.savefig(\n",
    "    \"Opt_Ensemble_Cho2017_bar_Group_fc_ens.pdf\",\n",
    "    dpi=300,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
